{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f914f64",
   "metadata": {},
   "source": [
    "# Test du chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d52395",
   "metadata": {},
   "source": [
    "## How does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8764a14d",
   "metadata": {},
   "source": [
    "The chatbot use a tsv file with two fields: Questions, answer\n",
    "The goal is that when a user enter a questions, using the glove vectors and the cosine similarity measure, we find the closest question matching the user sentence so as to find the closest answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eadabf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distance between two sentences using cosine similarity and glove for word representation\n",
    "def cosine_distance_sentence(sent1, sent2, weights1, weights2):\n",
    "  vector_1 = np.average([glove_vectors[word] for word in sent1 if word in glove_vectors], axis=0, weights=weights1)\n",
    "  vector_2 = np.average([glove_vectors[word] for word in sent2 if word in glove_vectors], axis=0, weights=weights2)\n",
    "  cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
    "  return 1 - cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890fada6",
   "metadata": {},
   "source": [
    "Each word have a weight associated to it coming from the tfidf matrix, for example the word 'it' is less important than the word 'plane' because it is less common in the whole corpus, but also for each question in that corpus.\n",
    "\n",
    "Also When computing the cosine we compare the question of the user to one of the question of the corpus. For the user's question we compute the weight of each word by taking the average of the value of that word on each document where it appears.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f698da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_dense_matrix(questions):\n",
    "  vectors = vectorizer.fit_transform(questions)\n",
    "  feature_names = vectorizer.get_feature_names()\n",
    "  dense = vectors.todense()\n",
    "  denselist = dense.tolist()\n",
    "  df = pd.DataFrame(denselist, columns=feature_names)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01588894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_questions_token(questions_tokens, dense_tfidf_matrix):\n",
    "  weight_matrix = []\n",
    "  for index, tokens in enumerate(questions_tokens):\n",
    "    weight_vector = []\n",
    "    for token in tokens:\n",
    "      if token in dense_tfidf_matrix.columns and token in glove_vectors:\n",
    "        weight_vector.append(dense_tfidf_matrix[token][index])\n",
    "      elif token in glove_vectors:\n",
    "        weight_vector.append(1.0)\n",
    "    weight_matrix.append(weight_vector)\n",
    "  return weight_matrix\n",
    "\n",
    "# using the information we have from the dense_tfidf_matrix we compute the weight vector\n",
    "def get_weights_new_sentences(sentence_tokens, dense_tfidf_matrix):\n",
    "  weight_vector = []\n",
    "  for token in sentence_tokens:\n",
    "    if token in dense_tfidf_matrix.columns and token in glove_vectors:\n",
    "      not_null_vector_token = dense_tfidf_matrix[token][dense_tfidf_matrix[token] > 0]\n",
    "      weight_vector.append(np.average(not_null_vector_token))\n",
    "    elif token in glove_vectors:\n",
    "      # we don't wan those weight vector to be longer than the on we use to\n",
    "      # make the np.average\n",
    "      weight_vector.append(1.0)\n",
    "  return weight_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f04b02",
   "metadata": {},
   "source": [
    "## An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9c70e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot_model import weight_matrix\n",
    "from chatbot_model import questions_tokens\n",
    "from chatbot_model import dense_tfidf_matrix\n",
    "from chatbot_model import weight_matrix\n",
    "from chatbot_model import predict_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e4b857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question closest to the sentence provided is \"how are you doing today?\"\n",
      "    --> i'm doing great. what about you?\n",
      "    (similarity is 0.9961597526733927)\n"
     ]
    }
   ],
   "source": [
    "question = 'how are you today?'\n",
    "\n",
    "answer, similarity = predict_answer(question, questions_tokens, dense_tfidf_matrix, weight_matrix, verbose=True)\n",
    "print(\"    --> {}\".format(answer))\n",
    "print(\"    (similarity is {})\".format(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a57d6be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question closest to the sentence provided is \"what school do you go to?\"\n",
      "    --> i go to pcc.\n",
      "    (similarity is 0.9958053079883509)\n"
     ]
    }
   ],
   "source": [
    "question = 'What school are you going to?'\n",
    "\n",
    "answer, similarity = predict_answer(question, questions_tokens, dense_tfidf_matrix, weight_matrix, verbose=True)\n",
    "print(\"    --> {}\".format(answer))\n",
    "print(\"    (similarity is {})\".format(similarity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
